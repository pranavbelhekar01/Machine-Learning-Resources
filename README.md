
# AI Daily Papers Repository

Welcome to the AI Daily Papers repository! ðŸš€ Stay updated with the latest and most impactful papers, articles, and books in the field of Artificial Intelligence.

## Table of Content
1. [Introduction](#introduction)
2. [Papers](#papers)
3. [Articles/Blogs](#articlesblogs)
4. [Books](https://github.com/pranavbelhekar01/Notes/blob/main/Books.md)
5. [How to Contribute](#how-to-contribute)
   

## Introduction
This repository is dedicated to curating and sharing daily insights from the world of Artificial Intelligence. Whether you are a researcher, student, or AI enthusiast, this collection aims to keep you informed about cutting-edge advancements in the field.

Feel free to explore the different sections and discover valuable resources that contribute to the ever-evolving landscape of AI.

## Papers
### 09 Jan 2024
1. [Mixtral of Experts](https://huggingface.co/papers/2401.04088)
2. [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://huggingface.co/papers/2401.04081)
3. [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://huggingface.co/papers/2401.02994)
4. [GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation](https://huggingface.co/papers/2401.04092)
5. [Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon](https://huggingface.co/papers/2401.03462)
6. [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://huggingface.co/papers/2401.03506)
7. [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](https://huggingface.co/papers/2401.03065)
8. [TeleChat Technical Report](https://huggingface.co/papers/2401.03804)
9. [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach](https://huggingface.co/papers/2401.02987)
10. [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding](https://huggingface.co/papers/2401.03003)
11. [AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://huggingface.co/login?next=%2Fpapers%2F2401.04099)

### 08 Jan 2024
1. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://huggingface.co/papers/2401.02954)
2. [Denoising Vision Transformers](https://huggingface.co/papers/2401.02957)
3. [Progressive Knowledge Distillation Of Stable Diffusion XL Using Layer Level Loss](https://huggingface.co/papers/2401.02677)
4. [DocGraphLM: Documental Graph Language Model for Information Extraction](https://huggingface.co/papers/2401.02823)
5. [Pheme: Efficient and Conversational Speech Generation](https://huggingface.co/papers/2401.02839)
6. [Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively](https://huggingface.co/login?next=%2Fpapers%2F2401.02955)
7. [Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache](https://huggingface.co/papers/2401.02669)

### 07 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
9. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
12. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 06 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
12. [LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 05 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
6. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
10. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
11. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
12. [LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 04 Jan 2024
1. [From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations](https://huggingface.co/papers/2401.01885)
2. [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://huggingface.co/login?next=%2Fpapers%2F2401.01614)
3. [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/papers/2401.01808)
4. [Image Sculpting: Precise Object Editing with 3D Geometry Control](https://huggingface.co/login?next=%2Fpapers%2F2401.01702)
5. [Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions](https://huggingface.co/papers/2401.01827)
6. [SIGNeRF: Scene Integrated Generation for Neural Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.01647)
7. [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://huggingface.co/papers/2401.01854)
8. [Incremental FastPitch: Chunk-based High Quality Text to Speech](https://huggingface.co/papers/2401.01755)
9. [CoMoSVC: Consistency Model-based Singing Voice Conversion](https://huggingface.co/papers/2401.01792)
10. [Efficient Hybrid Zoom using Camera Fusion on Mobile Phones](https://huggingface.co/papers/2401.01461)
11. [A Vision Check-up for Language Models](https://huggingface.co/papers/2401.01862)
12. [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope](https://huggingface.co/papers/2401.01699)

### 03 Jan 2024
1. [DocLLM: A layout-aware generative language model for multimodal document understanding](https://huggingface.co/papers/2401.00908)
2. [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://huggingface.co/papers/2401.01335)
3. [Boundary Attention: Learning to Find Faint Boundaries at Any Resolution](https://huggingface.co/papers/2401.00935)
4. [LLaMA Beyond English: An Empirical Study on Language Capability Transfer](https://huggingface.co/papers/2401.01055)
5. [Q-Refine: A Perceptual Quality Refiner for AI-Generated Image](https://huggingface.co/papers/2401.01117)
6. [TrailBlazer: Trajectory Control for Diffusion-Based Video Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00896)
7. [Taming Mode Collapse in Score Distillation for Text-to-3D Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00909)
8. [A Comprehensive Study of Knowledge Editing for Large Language Models](https://huggingface.co/papers/2401.01286)
9. [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://huggingface.co/papers/2401.01325)
10. [En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data](https://huggingface.co/papers/2401.01173)
11. [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM](https://huggingface.co/papers/2401.01256)

### 02 Jan 2024
1. [LARP: Language-Agent Role Play for Open-World Games](https://huggingface.co/papers/2312.17653)
2. [FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis](https://huggingface.co/papers/2312.17681)
3. [PanGu-$π$: Enhancing Language Model Architectures via Nonlinearity Compensation](https://huggingface.co/papers/2312.17276)
4. [Learning Vision from Models Rivals Learning Vision from Data](https://huggingface.co/papers/2312.17742)
5. [Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models](https://huggingface.co/papers/2312.17661)


## How to Contribute
Your contributions are highly valued! Feel free to contribute to the repository if you come across an interesting paper, article, or book. Follow these steps:
1. Fork the repository.
2. Add the paper, article, or book information to the corresponding section.
3. Create a pull request, and your contribution will be reviewed and merged.
4. Note: Please do not try to update the structure of the readme file.

Let's build an ever-growing resource together! ðŸ“šâœ¨

Enjoy exploring the world of AI!✈️


