
# AI Daily Papers Repository

Welcome to the AI Daily Papers repository! √∞≈∏≈°‚Ç¨ Stay updated with the latest and most impactful papers, articles, and books in the field of Artificial Intelligence.

## Table of Content
1. üìå[Introduction](#introduction) 
2. üöÄ[Papers](#papers)
3. ‚úàÔ∏è[Articles/Blogs](https://aiafternight.com/category/ai-feed/) 
4. üìö[Books](https://github.com/pranavbelhekar01/Machine-Learning-Resources/blob/main/sections/Books.md)
5. ü§ù[How to Contribute](#how-to-contribute)
   

## Introduction
This repository is dedicated to curating and sharing daily insights from the world of Artificial Intelligence. Whether you are a researcher, student, or AI enthusiast, this collection aims to keep you informed about cutting-edge advancements in the field.

Feel free to explore the different sections and discover valuable resources that contribute to the ever-evolving landscape of AI.

## Papers
### 18 Jan 2024
1. [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://huggingface.co/papers/2401.09417)
2. [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://huggingface.co/papers/2401.09340)
3. [ReFT: Reasoning with Reinforced Fine-Tuning](https://huggingface.co/papers/2401.08967)
4. [UniVG: Towards UNIfied-modal Video Generation](https://huggingface.co/papers/2401.09084)
5. [Asynchronous Local-SGD Training for Language Modeling](https://huggingface.co/papers/2401.09135)
6. [DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference](https://huggingface.co/papers/2401.08671)
7. [VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models](https://huggingface.co/papers/2401.09047)
8. [GARField: Group Anything with Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.09419)
9. [SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers](https://huggingface.co/papers/2401.08740)
10. [Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://huggingface.co/papers/2401.09048)
11. [ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://huggingface.co/papers/2401.08937)
12. [TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2401.09416)

### 16 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
7. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
8. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
9. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
10. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
11. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 14 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
11. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 13 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
11. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 12 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
8. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
9. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
10. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
11. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
12. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
13. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 11 Jan 2024
1. [PIXART-Œ¥: Fast and Controllable Image Generation with Latent Consistency Models](https://huggingface.co/papers/2401.05252)
2. [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://huggingface.co/login?next=%2Fpapers%2F2401.05335)
3. [URHand: Universal Relightable Hands](https://huggingface.co/login?next=%2Fpapers%2F2401.05334)
4. [The Impact of Reasoning Step Length on Large Language Models](https://huggingface.co/papers/2401.04925)
5. [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://huggingface.co/papers/2401.05033)
6. [Score Distillation Sampling with Learned Manifold Corrective](https://huggingface.co/papers/2401.05293)
7. [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://huggingface.co/papers/2401.05314)

### 10 Jan 2024
1. [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation](https://huggingface.co/papers/2401.04468)
2. [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models](https://huggingface.co/papers/2401.04658)
3. [Masked Audio Generation using a Single Non-Autoregressive Transformer](https://huggingface.co/papers/2401.04577)
4. [Jump Cut Smoothing for Talking Heads](https://huggingface.co/login?next=%2Fpapers%2F2401.04718)
5. [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding](https://huggingface.co/papers/2401.04575)
6. [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding](https://huggingface.co/papers/2401.04398)
7. [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://huggingface.co/papers/2401.04695)
8. [FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for Acoustic Echo Cancellation](https://huggingface.co/papers/2401.04283)

### 09 Jan 2024
1. [Mixtral of Experts](https://huggingface.co/papers/2401.04088)
2. [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://huggingface.co/papers/2401.04081)
3. [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://huggingface.co/papers/2401.02994)
4. [GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation](https://huggingface.co/papers/2401.04092)
5. [Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon](https://huggingface.co/papers/2401.03462)
6. [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://huggingface.co/papers/2401.03506)
7. [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](https://huggingface.co/papers/2401.03065)
8. [TeleChat Technical Report](https://huggingface.co/papers/2401.03804)
9. [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach](https://huggingface.co/papers/2401.02987)
10. [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding](https://huggingface.co/papers/2401.03003)
11. [AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://huggingface.co/login?next=%2Fpapers%2F2401.04099)

### 08 Jan 2024
1. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://huggingface.co/papers/2401.02954)
2. [Denoising Vision Transformers](https://huggingface.co/papers/2401.02957)
3. [Progressive Knowledge Distillation Of Stable Diffusion XL Using Layer Level Loss](https://huggingface.co/papers/2401.02677)
4. [DocGraphLM: Documental Graph Language Model for Information Extraction](https://huggingface.co/papers/2401.02823)
5. [Pheme: Efficient and Conversational Speech Generation](https://huggingface.co/papers/2401.02839)
6. [Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively](https://huggingface.co/login?next=%2Fpapers%2F2401.02955)
7. [Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache](https://huggingface.co/papers/2401.02669)

### 07 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
9. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
12. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 06 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 05 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
6. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
10. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
11. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 04 Jan 2024
1. [From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations](https://huggingface.co/papers/2401.01885)
2. [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://huggingface.co/login?next=%2Fpapers%2F2401.01614)
3. [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/papers/2401.01808)
4. [Image Sculpting: Precise Object Editing with 3D Geometry Control](https://huggingface.co/login?next=%2Fpapers%2F2401.01702)
5. [Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions](https://huggingface.co/papers/2401.01827)
6. [SIGNeRF: Scene Integrated Generation for Neural Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.01647)
7. [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://huggingface.co/papers/2401.01854)
8. [Incremental FastPitch: Chunk-based High Quality Text to Speech](https://huggingface.co/papers/2401.01755)
9. [CoMoSVC: Consistency Model-based Singing Voice Conversion](https://huggingface.co/papers/2401.01792)
10. [Efficient Hybrid Zoom using Camera Fusion on Mobile Phones](https://huggingface.co/papers/2401.01461)
11. [A Vision Check-up for Language Models](https://huggingface.co/papers/2401.01862)
12. [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope](https://huggingface.co/papers/2401.01699)

### 03 Jan 2024
1. [DocLLM: A layout-aware generative language model for multimodal document understanding](https://huggingface.co/papers/2401.00908)
2. [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://huggingface.co/papers/2401.01335)
3. [Boundary Attention: Learning to Find Faint Boundaries at Any Resolution](https://huggingface.co/papers/2401.00935)
4. [LLaMA Beyond English: An Empirical Study on Language Capability Transfer](https://huggingface.co/papers/2401.01055)
5. [Q-Refine: A Perceptual Quality Refiner for AI-Generated Image](https://huggingface.co/papers/2401.01117)
6. [TrailBlazer: Trajectory Control for Diffusion-Based Video Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00896)
7. [Taming Mode Collapse in Score Distillation for Text-to-3D Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00909)
8. [A Comprehensive Study of Knowledge Editing for Large Language Models](https://huggingface.co/papers/2401.01286)
9. [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://huggingface.co/papers/2401.01325)
10. [En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data](https://huggingface.co/papers/2401.01173)
11. [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM](https://huggingface.co/papers/2401.01256)

### 02 Jan 2024
1. [LARP: Language-Agent Role Play for Open-World Games](https://huggingface.co/papers/2312.17653)
2. [FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis](https://huggingface.co/papers/2312.17681)
3. [PanGu-$œÄ$: Enhancing Language Model Architectures via Nonlinearity Compensation](https://huggingface.co/papers/2312.17276)
4. [Learning Vision from Models Rivals Learning Vision from Data](https://huggingface.co/papers/2312.17742)
5. [Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models](https://huggingface.co/papers/2312.17661)




## How to Contribute
Your contributions are highly valued! Feel free to contribute to the repository if you come across an interesting paper, article, or book. Follow these steps:
1. Fork the repository.
2. Add the paper, article, or book information to the corresponding section.
3. Create a pull request, and your contribution will be reviewed and merged.
4. Note: Please do not try to update the structure of the readme file.

Let's build an ever-growing resource together! √∞≈∏‚Äú≈°√¢≈ì¬®

Enjoy exploring the world of AI!‚úàÔ∏è


