
# AI Daily Papers Repository

Welcome to the AI Daily Papers repository! √∞≈∏≈°‚Ç¨ Stay updated with the latest and most impactful papers, articles, and books in the field of Artificial Intelligence.

## Table of Content
1. üìå[Introduction](#introduction) 
2. üöÄ[Papers](#papers)
3. ‚úàÔ∏è[Articles/Blogs](https://aiafternight.com/category/ai-feed/) 
4. üìö[Books](https://github.com/pranavbelhekar01/Machine-Learning-Resources/blob/main/sections/Books.md)
5. ü§ù[How to Contribute](#how-to-contribute)
   
## Introduction
This repository is dedicated to curating and sharing daily insights from the world of Artificial Intelligence. Whether you are a researcher, student, or AI enthusiast, this collection aims to keep you informed about cutting-edge advancements in the field.

Feel free to explore the different sections and discover valuable resources that contribute to the ever-evolving landscape of AI.

## Papers
### 19 Feb 2024
1. [In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss](https://huggingface.co/papers/2402.10790)
2. [GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting](https://huggingface.co/login?next=%2Fpapers%2F2402.10259)
3. [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://huggingface.co/papers/2402.10379)
4. [LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models](https://huggingface.co/papers/2402.10524)
5. [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://huggingface.co/papers/2402.10466)
6. [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://huggingface.co/papers/2402.10294)
7. [Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation](https://huggingface.co/papers/2402.10491)
8. [Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots](https://huggingface.co/login?next=%2Fpapers%2F2402.10329)
9. [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter](https://huggingface.co/papers/2402.10896)
10. [RLVF: Learning from Verbal Feedback without Overgeneralization](https://huggingface.co/papers/2402.10893)
11. [SPAR: Personalized Content-Based Recommendation via Long Engagement Attention](https://huggingface.co/papers/2402.10555)
12. [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://huggingface.co/papers/2402.10644)

### 15 Feb 2024
1. [Magic-Me: Identity-Specific Video Customized Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.09368)
2. [Premise Order Matters in Reasoning with Large Language Models](https://huggingface.co/papers/2402.08939)
3. [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://huggingface.co/papers/2402.09052)
4. [Transformers Can Achieve Length Generalization But Not Robustly](https://huggingface.co/papers/2402.09371)
5. [Computing Power and the Governance of Artificial Intelligence](https://huggingface.co/papers/2402.08797)
6. [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://huggingface.co/login?next=%2Fpapers%2F2402.08714)
7. [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://huggingface.co/papers/2402.09126)
8. [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://huggingface.co/papers/2402.08855)
9. [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://huggingface.co/papers/2402.08958)

### 15 Feb 2024
1. [Magic-Me: Identity-Specific Video Customized Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.09368)
2. [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://huggingface.co/papers/2402.09052)
3. [Transformers Can Achieve Length Generalization But Not Robustly](https://huggingface.co/papers/2402.09371)
4. [Premise Order Matters in Reasoning with Large Language Models](https://huggingface.co/papers/2402.08939)
5. [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://huggingface.co/papers/2402.08855)
6. [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://huggingface.co/login?next=%2Fpapers%2F2402.08714)
7. [Computing Power and the Governance of Artificial Intelligence](https://huggingface.co/papers/2402.08797)
8. [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://huggingface.co/papers/2402.08958)
9. [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://huggingface.co/papers/2402.09126)

### 13 Feb 2024
1. [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://huggingface.co/papers/2402.07827)
2. [OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://huggingface.co/login?next=%2Fpapers%2F2402.07456)
3. [ChemLLM: A Chemical Large Language Model](https://huggingface.co/papers/2402.06852)
4. [Policy Improvement using Language Feedback Models](https://huggingface.co/papers/2402.07876)
5. [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://huggingface.co/papers/2402.07383)
6. [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://huggingface.co/papers/2402.07033)
7. [ODIN: Disentangled Reward Mitigates Hacking in RLHF](https://huggingface.co/papers/2402.07319)
8. [PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://huggingface.co/papers/2402.07872)
9. [Scaling Laws for Fine-Grained Mixture of Experts](https://huggingface.co/papers/2402.07871)
10. [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://huggingface.co/papers/2402.07625)
11. [A Tale of Tails: Model Collapse as a Change of Scaling Laws](https://huggingface.co/papers/2402.07043)
12. [Suppressing Pink Elephants with Direct Principle Feedback](https://huggingface.co/papers/2402.07896)
13. [LiRank: Industrial Large Scale Ranking Models at LinkedIn](https://huggingface.co/papers/2402.06859)
14. [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://huggingface.co/papers/2402.07865)
15. [Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping](https://huggingface.co/papers/2402.07610)
16. [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://huggingface.co/login?next=%2Fpapers%2F2402.07207)

### 12 Feb 2024
1. [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://huggingface.co/papers/2402.06118)
2. [HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://huggingface.co/papers/2402.06149)
3. [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://huggingface.co/papers/2402.06619)
4. [MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models](https://huggingface.co/papers/2402.06178)
5. [InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning](https://huggingface.co/papers/2402.06332)
6. [Keyframer: Empowering Animation Design using Large Language Models](https://huggingface.co/papers/2402.06071)
7. [SubGen: Token Generation in Sublinear Time and Memory](https://huggingface.co/papers/2402.06082)
8. [DeAL: Decoding-time Alignment for Large Language Models](https://huggingface.co/papers/2402.06147)
9. [Model Editing with Canonical Examples](https://huggingface.co/papers/2402.06155)
10. [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://huggingface.co/papers/2402.06088)
11. [Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning](https://huggingface.co/papers/2402.06102)
12. [Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss](https://huggingface.co/papers/2402.06187)

### 09 Feb 2024
1. [More Agents Is All You Need](https://huggingface.co/papers/2402.05120)
2. [$Œª$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space](https://huggingface.co/papers/2402.05195)
3. [Multilingual E5 Text Embeddings: A Technical Report](https://huggingface.co/papers/2402.05672)
4. [SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models](https://huggingface.co/papers/2402.05935)
5. [WebLINX: Real-World Website Navigation with Multi-Turn Dialogue](https://huggingface.co/login?next=%2Fpapers%2F2402.05930)
6. [Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains](https://huggingface.co/papers/2402.05140)
7. [An Interactive Agent Foundation Model](https://huggingface.co/papers/2402.05929)
8. [Memory Consolidation Enables Long-Context Video Understanding](https://huggingface.co/papers/2402.05861)
9. [Offline Actor-Critic Reinforcement Learning Scales to Large Models](https://huggingface.co/papers/2402.05546)
10. [In-Context Principle Learning from Mistakes](https://huggingface.co/papers/2402.05403)
11. [Implicit Diffusion: Efficient Optimization through Stochastic Sampling](https://huggingface.co/papers/2402.05468)
12. [SpiRit-LM: Interleaved Spoken and Written Language Model](https://huggingface.co/papers/2402.05755)
13. [Question Aware Vision Transformer for Multimodal Reasoning](https://huggingface.co/papers/2402.05472)
14. [InstaGen: Enhancing Object Detection by Training on Synthetic Dataset](https://huggingface.co/papers/2402.05937)
15. [Driving Everywhere with Large Language Model Policy Adaptation](https://huggingface.co/papers/2402.05932)

### 08 Feb 2024
1. [ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation](https://huggingface.co/papers/2402.04324)
2. [Direct Language Model Alignment from Online AI Feedback](https://huggingface.co/papers/2402.04792)
3. [BiLLM: Pushing the Limit of Post-Training Quantization for LLMs](https://huggingface.co/papers/2402.04291)
4. [ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://huggingface.co/papers/2402.04615)
5. [TP-Aware Dequantization](https://huggingface.co/papers/2402.04925)
6. [Fine-Tuned Language Models Generate Stable Inorganic Materials as Text](https://huggingface.co/papers/2402.04379)
7. [Hydragen: High-Throughput LLM Inference with Shared Prefixes](https://huggingface.co/papers/2402.05099)
8. [CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay](https://huggingface.co/papers/2402.04858)
9. [Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers](https://huggingface.co/papers/2402.04744)

### 05 Feb 2024
1. [StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback](https://huggingface.co/papers/2402.01391)
2. [Specialized Language Models with Cheap Inference from Limited Domain Data](https://huggingface.co/papers/2402.01093)
3. [Pok√©LLMon: A Human-Parity Agent for Pok√©mon Battles with Large Language Models](https://huggingface.co/papers/2402.01118)
4. [K-Level Reasoning with Large Language Models](https://huggingface.co/papers/2402.01521)
5. [TravelPlanner: A Benchmark for Real-World Planning with Language Agents](https://huggingface.co/papers/2402.01622)
6. [Boximator: Generating Rich and Controllable Motions for Video Synthesis](https://huggingface.co/login?next=%2Fpapers%2F2402.01566)
7. [Repeat After Me: Transformers are Better than State Space Models at Copying](https://huggingface.co/papers/2402.01032)
8. [EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks](https://huggingface.co/papers/2402.00892)
9. [Nomic Embed: Training a Reproducible Long Context Text Embedder](https://huggingface.co/papers/2402.01613)

### 04 Feb 2024
1. [OLMo: Accelerating the Science of Language Models](https://huggingface.co/papers/2402.00838)
2. [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://huggingface.co/papers/2402.00159)
3. [CroissantLLM: A Truly Bilingual French-English Language Model](https://huggingface.co/papers/2402.00786)
4. [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://huggingface.co/login?next=%2Fpapers%2F2402.00769)
5. [Can Large Language Models Understand Context?](https://huggingface.co/papers/2402.00858)
6. [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://huggingface.co/papers/2402.00854)
7. [Efficient Exploration for LLMs](https://huggingface.co/papers/2402.00396)
8. [Machine Unlearning for Image-to-Image Generative Models](https://huggingface.co/papers/2402.00351)
9. [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://huggingface.co/papers/2402.00867)
10. [Transforming and Combining Rewards for Aligning Large Language Models](https://huggingface.co/papers/2402.00742)
11. [EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models](https://huggingface.co/papers/2402.00518)

### 04 Feb 2024
1. [OLMo: Accelerating the Science of Language Models](https://huggingface.co/papers/2402.00838)
2. [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://huggingface.co/papers/2402.00159)
3. [CroissantLLM: A Truly Bilingual French-English Language Model](https://huggingface.co/papers/2402.00786)
4. [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://huggingface.co/login?next=%2Fpapers%2F2402.00769)
5. [Can Large Language Models Understand Context?](https://huggingface.co/papers/2402.00858)
6. [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://huggingface.co/papers/2402.00854)
7. [Efficient Exploration for LLMs](https://huggingface.co/papers/2402.00396)
8. [Machine Unlearning for Image-to-Image Generative Models](https://huggingface.co/papers/2402.00351)
9. [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://huggingface.co/papers/2402.00867)
10. [Transforming and Combining Rewards for Aligning Large Language Models](https://huggingface.co/papers/2402.00742)
11. [EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models](https://huggingface.co/papers/2402.00518)

### 31 Jan 2024
1. [Weaver: Foundation Models for Creative Writing](https://huggingface.co/papers/2401.17268)
2. [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://huggingface.co/login?next=%2Fpapers%2F2401.17053)
3. [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://huggingface.co/papers/2401.17270)
4. [Proactive Detection of Voice Cloning with Localized Watermarking](https://huggingface.co/papers/2401.17264)
5. [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://huggingface.co/papers/2401.17093)
6. [Weak-to-Strong Jailbreaking on Large Language Models](https://huggingface.co/papers/2401.17256)
7. [Transfer Learning for Text Diffusion Models](https://huggingface.co/papers/2401.17181)
8. [Repositioning the Subject within Image](https://huggingface.co/login?next=%2Fpapers%2F2401.16861)
9. [OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer](https://huggingface.co/papers/2401.16658)
10. [High-Quality Image Restoration Following Human Instructions](https://huggingface.co/papers/2401.16468)
11. [H2O-Danube-1.8B Technical Report](https://huggingface.co/papers/2401.16818)
12. [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://huggingface.co/papers/2401.16467)
13. [MouSi: Poly-Visual-Expert Vision-Language Models](https://huggingface.co/papers/2401.17221)
14. [T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives](https://huggingface.co/papers/2401.16677)

### 27 Jan 2024
1. [Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://huggingface.co/login?next=%2Fpapers%2F2401.13795)
2. [Rethinking Patch Dependence for Masked Autoencoders](https://huggingface.co/papers/2401.14391)
3. [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence](https://huggingface.co/papers/2401.14196)
4. [Deconstructing Denoising Diffusion Models for Self-Supervised Learning](https://huggingface.co/papers/2401.14404)
5. [Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI](https://huggingface.co/login?next=%2Fpapers%2F2401.14019)
6. [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://huggingface.co/papers/2401.13919)
7. [Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities](https://huggingface.co/papers/2401.14405)
8. [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://huggingface.co/papers/2401.13974)
9. [pix2gestalt: Amodal Segmentation by Synthesizing Wholes](https://huggingface.co/login?next=%2Fpapers%2F2401.14398)
10. [FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design](https://huggingface.co/papers/2401.14112)
11. [Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation](https://huggingface.co/papers/2401.14257)
12. [Adaptive Mobile Manipulation for Articulated Objects In the Open World](https://huggingface.co/login?next=%2Fpapers%2F2401.14403)
13. [Genie: Achieving Human Parity in Content-Grounded Datasets Generation](https://huggingface.co/papers/2401.14367)
14. [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://huggingface.co/papers/2401.14066)

### 25 Jan 2024
1. [Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://huggingface.co/papers/2401.13627)
2. [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://huggingface.co/papers/2401.13601)
3. [MambaByte: Token-free Selective State Space Model](https://huggingface.co/papers/2401.13660)
4. [SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection](https://huggingface.co/papers/2401.13160)
5. [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://huggingface.co/papers/2401.13388)
6. [MaLA-500: Massive Language Adaptation of Large Language Models](https://huggingface.co/papers/2401.13303)
7. [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://huggingface.co/papers/2401.13311)

### 20 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
3. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
4. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
5. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
6. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
7. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
8. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
9. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)
10. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)

### 20 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
3. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
4. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
5. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
6. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
7. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
8. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
9. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)
10. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)

### 19 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
3. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
4. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
5. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
6. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
7. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
8. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
9. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)
10. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)

### 18 Jan 2024
1. [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://huggingface.co/papers/2401.09417)
2. [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://huggingface.co/papers/2401.09340)
3. [ReFT: Reasoning with Reinforced Fine-Tuning](https://huggingface.co/papers/2401.08967)
4. [UniVG: Towards UNIfied-modal Video Generation](https://huggingface.co/papers/2401.09084)
5. [Asynchronous Local-SGD Training for Language Modeling](https://huggingface.co/papers/2401.09135)
6. [DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference](https://huggingface.co/papers/2401.08671)
7. [VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models](https://huggingface.co/papers/2401.09047)
8. [GARField: Group Anything with Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.09419)
9. [SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers](https://huggingface.co/papers/2401.08740)
10. [Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://huggingface.co/papers/2401.09048)
11. [ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://huggingface.co/papers/2401.08937)
12. [TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2401.09416)

### 16 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
7. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
8. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
9. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
10. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
11. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 14 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
11. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 13 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
11. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 12 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
8. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
9. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
10. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
11. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
12. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
13. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 11 Jan 2024
1. [PIXART-Œ¥: Fast and Controllable Image Generation with Latent Consistency Models](https://huggingface.co/papers/2401.05252)
2. [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://huggingface.co/login?next=%2Fpapers%2F2401.05335)
3. [URHand: Universal Relightable Hands](https://huggingface.co/login?next=%2Fpapers%2F2401.05334)
4. [The Impact of Reasoning Step Length on Large Language Models](https://huggingface.co/papers/2401.04925)
5. [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://huggingface.co/papers/2401.05033)
6. [Score Distillation Sampling with Learned Manifold Corrective](https://huggingface.co/papers/2401.05293)
7. [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://huggingface.co/papers/2401.05314)

### 10 Jan 2024
1. [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation](https://huggingface.co/papers/2401.04468)
2. [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models](https://huggingface.co/papers/2401.04658)
3. [Masked Audio Generation using a Single Non-Autoregressive Transformer](https://huggingface.co/papers/2401.04577)
4. [Jump Cut Smoothing for Talking Heads](https://huggingface.co/login?next=%2Fpapers%2F2401.04718)
5. [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding](https://huggingface.co/papers/2401.04575)
6. [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding](https://huggingface.co/papers/2401.04398)
7. [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://huggingface.co/papers/2401.04695)
8. [FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for Acoustic Echo Cancellation](https://huggingface.co/papers/2401.04283)

### 09 Jan 2024
1. [Mixtral of Experts](https://huggingface.co/papers/2401.04088)
2. [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://huggingface.co/papers/2401.04081)
3. [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://huggingface.co/papers/2401.02994)
4. [GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation](https://huggingface.co/papers/2401.04092)
5. [Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon](https://huggingface.co/papers/2401.03462)
6. [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://huggingface.co/papers/2401.03506)
7. [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](https://huggingface.co/papers/2401.03065)
8. [TeleChat Technical Report](https://huggingface.co/papers/2401.03804)
9. [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach](https://huggingface.co/papers/2401.02987)
10. [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding](https://huggingface.co/papers/2401.03003)
11. [AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://huggingface.co/login?next=%2Fpapers%2F2401.04099)

### 08 Jan 2024
1. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://huggingface.co/papers/2401.02954)
2. [Denoising Vision Transformers](https://huggingface.co/papers/2401.02957)
3. [Progressive Knowledge Distillation Of Stable Diffusion XL Using Layer Level Loss](https://huggingface.co/papers/2401.02677)
4. [DocGraphLM: Documental Graph Language Model for Information Extraction](https://huggingface.co/papers/2401.02823)
5. [Pheme: Efficient and Conversational Speech Generation](https://huggingface.co/papers/2401.02839)
6. [Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively](https://huggingface.co/login?next=%2Fpapers%2F2401.02955)
7. [Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache](https://huggingface.co/papers/2401.02669)

### 07 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
9. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
12. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 06 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 05 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
6. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
10. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
11. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 04 Jan 2024
1. [From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations](https://huggingface.co/papers/2401.01885)
2. [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://huggingface.co/login?next=%2Fpapers%2F2401.01614)
3. [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/papers/2401.01808)
4. [Image Sculpting: Precise Object Editing with 3D Geometry Control](https://huggingface.co/login?next=%2Fpapers%2F2401.01702)
5. [Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions](https://huggingface.co/papers/2401.01827)
6. [SIGNeRF: Scene Integrated Generation for Neural Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.01647)
7. [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://huggingface.co/papers/2401.01854)
8. [Incremental FastPitch: Chunk-based High Quality Text to Speech](https://huggingface.co/papers/2401.01755)
9. [CoMoSVC: Consistency Model-based Singing Voice Conversion](https://huggingface.co/papers/2401.01792)
10. [Efficient Hybrid Zoom using Camera Fusion on Mobile Phones](https://huggingface.co/papers/2401.01461)
11. [A Vision Check-up for Language Models](https://huggingface.co/papers/2401.01862)
12. [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope](https://huggingface.co/papers/2401.01699)

### 03 Jan 2024
1. [DocLLM: A layout-aware generative language model for multimodal document understanding](https://huggingface.co/papers/2401.00908)
2. [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://huggingface.co/papers/2401.01335)
3. [Boundary Attention: Learning to Find Faint Boundaries at Any Resolution](https://huggingface.co/papers/2401.00935)
4. [LLaMA Beyond English: An Empirical Study on Language Capability Transfer](https://huggingface.co/papers/2401.01055)
5. [Q-Refine: A Perceptual Quality Refiner for AI-Generated Image](https://huggingface.co/papers/2401.01117)
6. [TrailBlazer: Trajectory Control for Diffusion-Based Video Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00896)
7. [Taming Mode Collapse in Score Distillation for Text-to-3D Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00909)
8. [A Comprehensive Study of Knowledge Editing for Large Language Models](https://huggingface.co/papers/2401.01286)
9. [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://huggingface.co/papers/2401.01325)
10. [En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data](https://huggingface.co/papers/2401.01173)
11. [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM](https://huggingface.co/papers/2401.01256)

### 02 Jan 2024
1. [LARP: Language-Agent Role Play for Open-World Games](https://huggingface.co/papers/2312.17653)
2. [FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis](https://huggingface.co/papers/2312.17681)
3. [PanGu-$œÄ$: Enhancing Language Model Architectures via Nonlinearity Compensation](https://huggingface.co/papers/2312.17276)
4. [Learning Vision from Models Rivals Learning Vision from Data](https://huggingface.co/papers/2312.17742)
5. [Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models](https://huggingface.co/papers/2312.17661)




## How to Contribute
Your contributions are highly valued! Feel free to contribute to the repository if you come across an interesting paper, article, or book. Follow these steps:
1. Fork the repository.
2. Add the paper, article, or book information to the corresponding section.
3. Create a pull request, and your contribution will be reviewed and merged.
4. Note: Please do not try to update the structure of the readme file.

Let's build an ever-growing resource together! √∞≈∏‚Äú≈°√¢≈ì¬®

Enjoy exploring the world of AI!‚úàÔ∏è


