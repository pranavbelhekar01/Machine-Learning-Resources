


# AI Daily Papers Repository

Welcome to the AI Daily Papers repository! √∞≈∏≈°‚Ç¨ Stay updated with the latest and most impactful papers, articles, and books in the field of Artificial Intelligence.

## Table of Content
1. üìå[Introduction](#introduction) 
2. üöÄ[Papers](#papers)
3. ‚úàÔ∏è[Articles/Blogs](https://aiafternight.com/category/ai-feed/) 
4. üìö[Books](https://github.com/pranavbelhekar01/Machine-Learning-Resources/blob/main/sections/Books.md)
5. ü§ù[How to Contribute](#how-to-contribute)
   
## Introduction
This repository is dedicated to curating and sharing daily insights from the world of Artificial Intelligence. Whether you are a researcher, student, or AI enthusiast, this collection aims to keep you informed about cutting-edge advancements in the field.

Feel free to explore the different sections and discover valuable resources that contribute to the ever-evolving landscape of AI.

## Papers
### 01 Aug 2024

### 30 Jul 2024

### 19 Jul 2024

### 18 Jul 2024

### 30 May 2024
1. [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](https://huggingface.co/papers/2405.19327)
2. [LLMs achieve adult human performance on higher-order theory of mind tasks](https://huggingface.co/papers/2405.18870)
3. [T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback](https://huggingface.co/papers/2405.18750)
4. [NPGA: Neural Parametric Gaussian Avatars](https://huggingface.co/papers/2405.19331)
5. [SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation](https://huggingface.co/papers/2405.18503)
6. [Atlas3D: Physically Constrained Self-Supporting Text-to-3D for Simulation and Fabrication](https://huggingface.co/papers/2405.18515)
7. [EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture](https://huggingface.co/papers/2405.18991)
8. [Offline Regularised Reinforcement Learning for Large Language Models Alignment](https://huggingface.co/papers/2405.19107)
9. [Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities](https://huggingface.co/papers/2405.18669)
10. [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://huggingface.co/papers/2405.19325)
11. [Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF](https://huggingface.co/papers/2405.19320)
12. [Self-Exploring Language Models: Active Preference Elicitation for Online Alignment](https://huggingface.co/papers/2405.19332)

### 18 May 2024
1. [Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://huggingface.co/papers/2405.09818)
2. [LoRA Learns Less and Forgets Less](https://huggingface.co/papers/2405.09673)
3. [Many-Shot In-Context Learning in Multimodal Foundation Models](https://huggingface.co/papers/2405.09798)
4. [CAT3D: Create Anything in 3D with Multi-View Diffusion Models](https://huggingface.co/papers/2405.10314)
5. [Grounding DINO 1.5: Advance the "Edge" of Open-Set Object Detection](https://huggingface.co/papers/2405.10300)
6. [Dual3D: Efficient and Consistent Text-to-3D Generation with Dual-mode Multi-view Latent Diffusion](https://huggingface.co/papers/2405.09874)
7. [Toon3D: Seeing Cartoons from a New Perspective](https://huggingface.co/papers/2405.10320)
8. [TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction](https://huggingface.co/papers/2405.10315)

### 17 May 2024
1. [Dual3D: Efficient and Consistent Text-to-3D Generation with Dual-mode Multi-view Latent Diffusion](https://huggingface.co/papers/2405.09874)
2. [Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://huggingface.co/papers/2405.09818)

### 08 May 2024
1. [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](https://huggingface.co/papers/2405.00732)
2. [Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models](https://huggingface.co/papers/2405.01535)
3. [WildChat: 1M ChatGPT Interaction Logs in the Wild](https://huggingface.co/papers/2405.01470)
4. [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](https://huggingface.co/papers/2405.01434)
5. [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](https://huggingface.co/papers/2405.01481)
6. [FLAME: Factuality-Aware Alignment for Large Language Models](https://huggingface.co/papers/2405.01525)
7. [Customizing Text-to-Image Models with a Single Image Pair](https://huggingface.co/papers/2405.01536)
8. [LLM-AD: Large Language Model based Audio Description System](https://huggingface.co/papers/2405.00983)

### 23 Apr 2024
1. [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://huggingface.co/papers/2404.14219)
2. [The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions](https://huggingface.co/papers/2404.13208)
3. [How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study](https://huggingface.co/papers/2404.14047)
4. [Hyper-SD: Trajectory Segmented Consistency Model for Efficient Image Synthesis](https://huggingface.co/papers/2404.13686)
5. [FlowMind: Automatic Workflow Generation with LLMs](https://huggingface.co/papers/2404.13050)
6. [A Multimodal Automated Interpretability Agent](https://huggingface.co/papers/2404.14394)
7. [SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation](https://huggingface.co/papers/2404.14396)
8. [Music Consistency Models](https://huggingface.co/papers/2404.13358)
9. [MultiBooth: Towards Generating All Your Concepts in an Image from Text](https://huggingface.co/papers/2404.14239)
10. [Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer](https://huggingface.co/papers/2404.14351)
11. [Learning H-Infinity Locomotion Control](https://huggingface.co/papers/2404.14405)

### 18 Apr 2024
1. [Long-form music generation with latent diffusion](https://huggingface.co/papers/2404.10301)
2. [Scaling Instructable Agents Across Many Simulated Worlds](https://huggingface.co/papers/2404.10179)

### 17 Apr 2024
1. [Scaling Instructable Agents Across Many Simulated Worlds](https://huggingface.co/papers/2404.10179)
2. [Long-form music generation with latent diffusion](https://huggingface.co/papers/2404.10301)

### 14 Apr 2024
1. [Rho-1: Not All Tokens Are What You Need](https://huggingface.co/papers/2404.07965)
2. [ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback](https://huggingface.co/papers/2404.07987)
3. [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://huggingface.co/papers/2404.07972)
4. [RecurrentGemma: Moving Past Transformers for Efficient Open Language Models](https://huggingface.co/papers/2404.07839)
5. [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](https://huggingface.co/papers/2404.07973)
6. [JetMoE: Reaching Llama2 Performance with 0.1M Dollars](https://huggingface.co/papers/2404.07413)
7. [Best Practices and Lessons Learned on Synthetic Data for Language Models](https://huggingface.co/papers/2404.07503)
8. [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](https://huggingface.co/papers/2404.05902)
9. [HGRN2: Gated Linear RNNs with State Expansion](https://huggingface.co/papers/2404.07904)
10. [From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples](https://huggingface.co/papers/2404.07544)
11. [Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models](https://huggingface.co/papers/2404.07724)
12. [LLoCO: Learning Long Contexts Offline](https://huggingface.co/papers/2404.07979)
13. [Audio Dialogues: Dialogues dataset for audio and music understanding](https://huggingface.co/papers/2404.07616)
14. [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](https://huggingface.co/papers/2404.07448)
15. [Sparse Laneformer](https://huggingface.co/papers/2404.07821)

### 14 Apr 2024
1. [Rho-1: Not All Tokens Are What You Need](https://huggingface.co/papers/2404.07965)
2. [ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback](https://huggingface.co/papers/2404.07987)
3. [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://huggingface.co/papers/2404.07972)
4. [RecurrentGemma: Moving Past Transformers for Efficient Open Language Models](https://huggingface.co/papers/2404.07839)
5. [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](https://huggingface.co/papers/2404.07973)
6. [JetMoE: Reaching Llama2 Performance with 0.1M Dollars](https://huggingface.co/papers/2404.07413)
7. [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](https://huggingface.co/papers/2404.05902)
8. [Best Practices and Lessons Learned on Synthetic Data for Language Models](https://huggingface.co/papers/2404.07503)
9. [HGRN2: Gated Linear RNNs with State Expansion](https://huggingface.co/papers/2404.07904)
10. [From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples](https://huggingface.co/papers/2404.07544)
11. [Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models](https://huggingface.co/papers/2404.07724)
12. [LLoCO: Learning Long Contexts Offline](https://huggingface.co/papers/2404.07979)
13. [Audio Dialogues: Dialogues dataset for audio and music understanding](https://huggingface.co/papers/2404.07616)
14. [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](https://huggingface.co/papers/2404.07448)
15. [Sparse Laneformer](https://huggingface.co/papers/2404.07821)

### 12 Apr 2024
1. [ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback](https://huggingface.co/papers/2404.07987)
2. [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://huggingface.co/papers/2404.07972)
3. [Rho-1: Not All Tokens Are What You Need](https://huggingface.co/papers/2404.07965)
4. [JetMoE: Reaching Llama2 Performance with 0.1M Dollars](https://huggingface.co/papers/2404.07413)
5. [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](https://huggingface.co/papers/2404.07448)
6. [LLoCO: Learning Long Contexts Offline](https://huggingface.co/papers/2404.07979)
7. [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](https://huggingface.co/papers/2404.07973)
8. [RecurrentGemma: Moving Past Transformers for Efficient Open Language Models](https://huggingface.co/papers/2404.07839)
9. [Best Practices and Lessons Learned on Synthetic Data for Language Models](https://huggingface.co/papers/2404.07503)
10. [Audio Dialogues: Dialogues dataset for audio and music understanding](https://huggingface.co/papers/2404.07616)
11. [From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples](https://huggingface.co/papers/2404.07544)
12. [Sparse Laneformer](https://huggingface.co/papers/2404.07821)
13. [Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models](https://huggingface.co/papers/2404.07724)

### 03 Apr 2024
1. [Advancing LLM Reasoning Generalists with Preference Trees](https://huggingface.co/papers/2404.02078)
2. [Octopus v2: On-device language model for super agent](https://huggingface.co/papers/2404.01744)
3. [Long-context LLMs Struggle with Long In-context Learning](https://huggingface.co/papers/2404.02060)
4. [Bigger is not Always Better: Scaling Properties of Latent Diffusion Models](https://huggingface.co/papers/2404.01367)
5. [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](https://huggingface.co/papers/2404.01331)
6. [Poro 34B and the Blessing of Multilinguality](https://huggingface.co/papers/2404.01856)
7. [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](https://huggingface.co/papers/2404.02101)
8. [HyperCLOVA X Technical Report](https://huggingface.co/papers/2404.01954)
9. [Are large language models superhuman chemists?](https://huggingface.co/papers/2404.01475)
10. [3D Congealing: 3D-Aware Image Alignment in the Wild](https://huggingface.co/papers/2404.02125)
11. [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](https://huggingface.co/papers/2404.01617)

### 30 Mar 2024
1. [sDPO: Don't Use Your Data All at Once](https://huggingface.co/papers/2403.19270)
2. [LITA: Language Instructed Temporal-Localization Assistant](https://huggingface.co/papers/2403.19046)
3. [GaussianCube: Structuring Gaussian Splatting using Optimal Transport for 3D Generative Modeling](https://huggingface.co/papers/2403.19655)
4. [TextCraftor: Your Text Encoder Can be Image Quality Controller](https://huggingface.co/papers/2403.18978)
5. [Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation](https://huggingface.co/papers/2403.19319)

### 28 Mar 2024
1. [Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models](https://huggingface.co/papers/2403.18814)
2. [BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text](https://huggingface.co/papers/2403.18421)
3. [ViTAR: Vision Transformer with Any Resolution](https://huggingface.co/papers/2403.18361)
4. [Garment3DGen: 3D Garment Stylization and Texture Generation](https://huggingface.co/papers/2403.18816)
5. [Long-form factuality in large language models](https://huggingface.co/papers/2403.18802)
6. [Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction](https://huggingface.co/papers/2403.18795)
7. [ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion](https://huggingface.co/papers/2403.18818)
8. [FlexEdit: Flexible and Controllable Diffusion-based Object-centric Image Editing](https://huggingface.co/papers/2403.18605)
9. [Towards a World-English Language Model for On-Device Virtual Assistants](https://huggingface.co/papers/2403.18783)
10. [EgoLifter: Open-world 3D Segmentation for Egocentric Perception](https://huggingface.co/papers/2403.18118)

### 26 Mar 2024
1. [LLM Agent Operating System](https://huggingface.co/papers/2403.16971)
2. [FlashFace: Human Image Personalization with High-fidelity Identity Preservation](https://huggingface.co/papers/2403.17008)
3. [Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation](https://huggingface.co/papers/2403.16990)
4. [Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://huggingface.co/papers/2403.15447)
5. [TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models](https://huggingface.co/papers/2403.17005)
6. [RakutenAI-7B: Extending Large Language Models for Japanese](https://huggingface.co/papers/2403.15484)
7. [VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation](https://huggingface.co/papers/2403.17001)
8. [SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions](https://huggingface.co/papers/2403.16627)

### 21 Mar 2024
1. [Mora: Enabling Generalist Video Generation via A Multi-Agent Framework](https://huggingface.co/papers/2403.13248)
2. [LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://huggingface.co/papers/2403.13372)
3. [SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model](https://huggingface.co/papers/2403.13064)
4. [Evolutionary Optimization of Model Merging Recipes](https://huggingface.co/papers/2403.13187)
5. [When Do We Not Need Larger Vision Models?](https://huggingface.co/papers/2403.13043)
6. [IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models](https://huggingface.co/papers/2403.13535)
7. [RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS](https://huggingface.co/papers/2403.13806)
8. [HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models](https://huggingface.co/papers/2403.13447)
9. [Magic Fixup: Streamlining Photo Editing by Watching Dynamic Videos](https://huggingface.co/papers/2403.13044)
10. [RewardBench: Evaluating Reward Models for Language Modeling](https://huggingface.co/papers/2403.13787)
11. [DepthFM: Fast Monocular Depth Estimation with Flow Matching](https://huggingface.co/papers/2403.13788)
12. [Be-Your-Outpainter: Mastering Video Outpainting through Input-Specific Adaptation](https://huggingface.co/papers/2403.13745)
13. [VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis](https://huggingface.co/papers/2403.13501)
14. [ZigMa: Zigzag Mamba Diffusion Model](https://huggingface.co/papers/2403.13802)
15. [Compress3D: a Compressed Latent Space for 3D Generation from a Single Image](https://huggingface.co/papers/2403.13524)
16. [Towards 3D Molecule-Text Interpretation in Language Models](https://huggingface.co/papers/2401.13923)
17. [Evaluating Frontier Models for Dangerous Capabilities](https://huggingface.co/papers/2403.13793)
18. [Reverse Training to Nurse the Reversal Curse](https://huggingface.co/papers/2403.13799)

### 19 Mar 2024
1. [Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation](https://huggingface.co/papers/2403.12015)
2. [PERL: Parameter Efficient Reinforcement Learning from Human Feedback](https://huggingface.co/papers/2403.10704)
3. [Larimar: Large Language Models with Episodic Memory Control](https://huggingface.co/papers/2403.11901)
4. [Generic 3D Diffusion Adapter Using Controlled Multi-View Editing](https://huggingface.co/papers/2403.12032)
5. [SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion](https://huggingface.co/papers/2403.12008)
6. [Infinite-ID: Identity-preserved Personalization via ID-semantics Decoupling Paradigm](https://huggingface.co/papers/2403.11781)
7. [LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images](https://huggingface.co/papers/2403.11703)
8. [LightIt: Illumination Modeling and Control for Diffusion Models](https://huggingface.co/papers/2403.10615)
9. [LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation](https://huggingface.co/papers/2403.12019)
10. [MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data](https://huggingface.co/papers/2403.11207)
11. [VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](https://huggingface.co/papers/2403.11481)
12. [VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models](https://huggingface.co/papers/2403.12034)
13. [DiPaCo: Distributed Path Composition](https://huggingface.co/papers/2403.10616)

### 18 Mar 2024
1. [Uni-SMART: Universal Science Multimodal Analysis and Research Transformer](https://huggingface.co/papers/2403.10301)
2. [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](https://huggingface.co/papers/2403.10517)
3. [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](https://huggingface.co/papers/2403.09919)
4. [RAFT: Adapting Language Model to Domain Specific RAG](https://huggingface.co/papers/2403.10131)
5. [Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations](https://huggingface.co/papers/2403.09704)
6. [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](https://huggingface.co/papers/2403.09977)
7. [MusicHiFi: Fast High-Fidelity Stereo Vocoding](https://huggingface.co/papers/2403.10493)
8. [Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding](https://huggingface.co/papers/2403.10395)
9. [Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting](https://huggingface.co/papers/2403.09981)

### 17 Mar 2024
1. [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://huggingface.co/papers/2403.09611)
2. [Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset](https://huggingface.co/papers/2403.09029)
3. [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://huggingface.co/papers/2403.09629)
4. [GiT: Towards Generalist Vision Transformer through Universal Language Interface](https://huggingface.co/papers/2403.09394)
5. [Video Editing via Factorized Diffusion Distillation](https://huggingface.co/papers/2403.09334)
6. [StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control](https://huggingface.co/papers/2403.09055)
7. [BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences](https://huggingface.co/papers/2403.09347)
8. [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](https://huggingface.co/papers/2403.09333)
9. [Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding](https://huggingface.co/papers/2403.09626)
10. [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](https://huggingface.co/papers/2403.09530)
11. [LocalMamba: Visual State Space Model with Windowed Selective Scan](https://huggingface.co/papers/2403.09338)
12. [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://huggingface.co/papers/2403.09631)
13. [Veagle: Advancements in Multimodal Representation Learning](https://huggingface.co/papers/2403.08773)
14. [Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering](https://huggingface.co/papers/2403.09622)

### 16 Mar 2024
1. [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://huggingface.co/papers/2403.09611)
2. [Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset](https://huggingface.co/papers/2403.09029)
3. [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://huggingface.co/papers/2403.09629)
4. [GiT: Towards Generalist Vision Transformer through Universal Language Interface](https://huggingface.co/papers/2403.09394)
5. [Video Editing via Factorized Diffusion Distillation](https://huggingface.co/papers/2403.09334)
6. [StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control](https://huggingface.co/papers/2403.09055)
7. [BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences](https://huggingface.co/papers/2403.09347)
8. [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](https://huggingface.co/papers/2403.09333)
9. [Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding](https://huggingface.co/papers/2403.09626)
10. [LocalMamba: Visual State Space Model with Windowed Selective Scan](https://huggingface.co/papers/2403.09338)
11. [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](https://huggingface.co/papers/2403.09530)
12. [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://huggingface.co/papers/2403.09631)
13. [Veagle: Advancements in Multimodal Representation Learning](https://huggingface.co/papers/2403.08773)
14. [Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering](https://huggingface.co/papers/2403.09622)

### 14 Mar 2024
1. [Gemma: Open Models Based on Gemini Research and Technology](https://huggingface.co/papers/2403.08295)
2. [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://huggingface.co/papers/2403.08763)
3. [VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis](https://huggingface.co/papers/2403.08764)
4. [Scaling Up Dynamic Human-Scene Interaction Modeling](https://huggingface.co/papers/2403.08629)
5. [Language models scale reliably with over-training and on downstream tasks](https://huggingface.co/papers/2403.08540)
6. [SOTOPIA-$œÄ$: Interactive Learning of Socially Intelligent Language Agents](https://huggingface.co/papers/2403.08715)
7. [On the Societal Impact of Open Foundation Models](https://huggingface.co/papers/2403.07918)
8. [Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts](https://huggingface.co/papers/2403.08268)
9. [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://huggingface.co/papers/2403.08551)

### 13 Mar 2024
1. [MoAI: Mixture of All Intelligence for Large Language and Vision Models](https://huggingface.co/papers/2403.07508)
2. [Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM](https://huggingface.co/papers/2403.07816)
3. [Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings](https://huggingface.co/papers/2403.07750)
4. [Chronos: Learning the Language of Time Series](https://huggingface.co/papers/2403.07815)
5. [Learning Generalizable Feature Fields for Mobile Manipulation](https://huggingface.co/papers/2403.07563)
6. [Motion Mamba: Efficient and Long Sequence Motion Generation with Hierarchical and Bidirectional Selective SSM](https://huggingface.co/papers/2403.07487)
7. [FAX: Scalable and Differentiable Federated Primitives in JAX](https://huggingface.co/papers/2403.07128)
8. [DragAnything: Motion Control for Anything using Entity Representation](https://huggingface.co/papers/2403.07420)

### 12 Mar 2024
1. [Stealing Part of a Production Language Model](https://huggingface.co/papers/2403.06634)
2. [Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU](https://huggingface.co/papers/2403.06504)
3. [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://huggingface.co/papers/2403.06764)
4. [VideoMamba: State Space Model for Efficient Video Understanding](https://huggingface.co/papers/2403.06977)
5. [Multistep Consistency Models](https://huggingface.co/papers/2403.06807)
6. [Algorithmic progress in language models](https://huggingface.co/papers/2403.05812)
7. [V3D: Video Diffusion Models are Effective 3D Generators](https://huggingface.co/papers/2403.06738)
8. [VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models](https://huggingface.co/papers/2403.06098)
9. [FaceChain-SuDe: Building Derived Class to Inherit Category Attributes for One-shot Subject-Driven Generation](https://huggingface.co/papers/2403.06775)

### 11 Mar 2024
1. [ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](https://huggingface.co/papers/2403.05135)
2. [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://huggingface.co/papers/2403.05530)
3. [DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://huggingface.co/papers/2403.05525)
4. [CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion](https://huggingface.co/papers/2403.05121)
5. [VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models](https://huggingface.co/papers/2403.05438)
6. [Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks](https://huggingface.co/papers/2403.05185)
7. [CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model](https://huggingface.co/papers/2403.05034)

### 08 Mar 2024
1. [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](https://huggingface.co/papers/2403.04132)
2. [Teaching Large Language Models to Reason with Reinforcement Learning](https://huggingface.co/papers/2403.04642)
3. [StableDrag: Stable Dragging for Point-based Image Editing](https://huggingface.co/papers/2403.04437)
4. [Common 7B Language Models Already Possess Strong Math Capabilities](https://huggingface.co/papers/2403.04706)
5. [Yi: Open Foundation Models by 01.AI](https://huggingface.co/papers/2403.04652)
6. [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](https://huggingface.co/papers/2403.04746)
7. [PixArt-Œ£: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation](https://huggingface.co/papers/2403.04692)
8. [How Far Are We from Intelligent Visual Deductive Reasoning?](https://huggingface.co/papers/2403.04732)
9. [Pix2Gif: Motion-Guided Diffusion for GIF Generation](https://huggingface.co/papers/2403.04634)
10. [Radiative Gaussian Splatting for Efficient X-ray Novel View Synthesis](https://huggingface.co/papers/2403.04116)

### 05 Mar 2024
1. [VisionLLaMA: A Unified LLaMA Interface for Vision Tasks](https://huggingface.co/papers/2403.00522)
2. [Learning and Leveraging World Models in Visual Representation Learning](https://huggingface.co/papers/2403.00504)
3. [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://huggingface.co/papers/2403.00071)
4. [AtP*: An efficient and scalable method for localizing LLM behaviour to components](https://huggingface.co/papers/2403.00745)
5. [RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization](https://huggingface.co/papers/2403.00483)

### 04 Mar 2024
1. [StarCoder 2 and The Stack v2: The Next Generation](https://huggingface.co/papers/2402.19173)
2. [Beyond Language Models: Byte Models are Digital World Simulators](https://huggingface.co/papers/2402.19155)
3. [Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](https://huggingface.co/papers/2402.19427)
4. [Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers](https://huggingface.co/papers/2402.19479)
5. [MOSAIC: A Modular System for Assistive and Interactive Cooking](https://huggingface.co/login?next=%2Fpapers%2F2402.18796)
6. [Humanoid Locomotion as Next Token Prediction](https://huggingface.co/login?next=%2Fpapers%2F2402.19469)
7. [Simple linear attention language models balance the recall-throughput tradeoff](https://huggingface.co/papers/2402.18668)
8. [Trajectory Consistency Distillation](https://huggingface.co/papers/2402.19159)
9. [ViewFusion: Towards Multi-View Consistency via Interpolated Denoising](https://huggingface.co/login?next=%2Fpapers%2F2402.18842)
10. [DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models](https://huggingface.co/papers/2402.19481)
11. [Priority Sampling of Large Language Models for Compilers](https://huggingface.co/papers/2402.18734)

### 03 Mar 2024
1. [StarCoder 2 and The Stack v2: The Next Generation](https://huggingface.co/papers/2402.19173)
2. [Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](https://huggingface.co/papers/2402.19427)
3. [Beyond Language Models: Byte Models are Digital World Simulators](https://huggingface.co/papers/2402.19155)
4. [Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers](https://huggingface.co/papers/2402.19479)
5. [Humanoid Locomotion as Next Token Prediction](https://huggingface.co/login?next=%2Fpapers%2F2402.19469)
6. [MOSAIC: A Modular System for Assistive and Interactive Cooking](https://huggingface.co/login?next=%2Fpapers%2F2402.18796)
7. [Simple linear attention language models balance the recall-throughput tradeoff](https://huggingface.co/papers/2402.18668)
8. [Trajectory Consistency Distillation](https://huggingface.co/papers/2402.19159)
9. [DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models](https://huggingface.co/papers/2402.19481)
10. [ViewFusion: Towards Multi-View Consistency via Interpolated Denoising](https://huggingface.co/login?next=%2Fpapers%2F2402.18842)
11. [Priority Sampling of Large Language Models for Compilers](https://huggingface.co/papers/2402.18734)

### 28 Feb 2024
1. [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://huggingface.co/papers/2402.17764)
2. [EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions](https://huggingface.co/papers/2402.17485)
3. [Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://huggingface.co/papers/2402.17177)
4. [DiffuseKronA: A Parameter Efficient Fine-tuning Method for Personalized Diffusion Model](https://huggingface.co/papers/2402.17412)
5. [Towards Optimal Learning of Language Models](https://huggingface.co/papers/2402.17759)
6. [Video as the New Language for Real-World Decision Making](https://huggingface.co/papers/2402.17139)
7. [Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners](https://huggingface.co/login?next=%2Fpapers%2F2402.17723)
8. [Sora Generates Videos with Stunning Geometrical Consistency](https://huggingface.co/papers/2402.17403)
9. [Disentangled 3D Scene Generation with Layout Learning](https://huggingface.co/papers/2402.16936)
10. [Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation](https://huggingface.co/papers/2402.17245)
11. [When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method](https://huggingface.co/papers/2402.17193)
12. [VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction](https://huggingface.co/papers/2402.17427)
13. [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://huggingface.co/papers/2402.17553)
14. [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://huggingface.co/papers/2402.17753)
15. [Training-Free Long-Context Scaling of Large Language Models](https://huggingface.co/papers/2402.17463)

### 25 Feb 2024
1. [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://huggingface.co/login?next=%2Fpapers%2F2402.14658)
2. [Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping](https://huggingface.co/papers/2402.14083)
3. [PALO: A Polyglot Large Multimodal Model for 5B People](https://huggingface.co/papers/2402.14818)
4. [Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis](https://huggingface.co/papers/2402.14797)
5. [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://huggingface.co/papers/2402.14034)
6. [OmniPred: Language Models as Universal Regressors](https://huggingface.co/papers/2402.14547)
7. [Subobject-level Image Tokenization](https://huggingface.co/papers/2402.14327)
8. [TinyLLaVA: A Framework of Small-scale Large Multimodal Models](https://huggingface.co/papers/2402.14289)
9. [GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.14810)
10. [T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching](https://huggingface.co/papers/2402.14167)
11. [LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons](https://huggingface.co/papers/2402.14086)
12. [Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming](https://huggingface.co/papers/2402.14261)
13. [GaussianPro: 3D Gaussian Splatting with Progressive Propagation](https://huggingface.co/login?next=%2Fpapers%2F2402.14650)
14. [Consolidating Attention Features for Multi-view Image Editing](https://huggingface.co/login?next=%2Fpapers%2F2402.14792)
15. [Scaling Up LLM Reviews for Google Ads Content Moderation](https://huggingface.co/papers/2402.14590)
16. [BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay](https://huggingface.co/papers/2402.14194)
17. [Linear Transformers are Versatile In-Context Learners](https://huggingface.co/papers/2402.14180)
18. [CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation](https://huggingface.co/papers/2402.14795)
19. [MVD$^2$: Efficient Multiview 3D Reconstruction for Multiview Diffusion](https://huggingface.co/papers/2402.14253)

### 24 Feb 2024
1. [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://huggingface.co/login?next=%2Fpapers%2F2402.14658)
2. [Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping](https://huggingface.co/papers/2402.14083)
3. [PALO: A Polyglot Large Multimodal Model for 5B People](https://huggingface.co/papers/2402.14818)
4. [Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis](https://huggingface.co/papers/2402.14797)
5. [Subobject-level Image Tokenization](https://huggingface.co/papers/2402.14327)
6. [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://huggingface.co/papers/2402.14034)
7. [TinyLLaVA: A Framework of Small-scale Large Multimodal Models](https://huggingface.co/papers/2402.14289)
8. [OmniPred: Language Models as Universal Regressors](https://huggingface.co/papers/2402.14547)
9. [LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons](https://huggingface.co/papers/2402.14086)
10. [T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching](https://huggingface.co/papers/2402.14167)
11. [GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.14810)
12. [GaussianPro: 3D Gaussian Splatting with Progressive Propagation](https://huggingface.co/login?next=%2Fpapers%2F2402.14650)
13. [Scaling Up LLM Reviews for Google Ads Content Moderation](https://huggingface.co/papers/2402.14590)
14. [Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming](https://huggingface.co/papers/2402.14261)
15. [CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation](https://huggingface.co/papers/2402.14795)
16. [BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay](https://huggingface.co/papers/2402.14194)
17. [MVD$^2$: Efficient Multiview 3D Reconstruction for Multiview Diffusion](https://huggingface.co/papers/2402.14253)
18. [Linear Transformers are Versatile In-Context Learners](https://huggingface.co/papers/2402.14180)
19. [Consolidating Attention Features for Multi-view Image Editing](https://huggingface.co/login?next=%2Fpapers%2F2402.14792)

### 21 Feb 2024
1. [Neural Network Diffusion](https://huggingface.co/papers/2402.13144)
2. [Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models](https://huggingface.co/papers/2402.13064)
3. [Improving Robustness for Joint Optimization of Camera Poses and Decomposed Low-Rank Tensorial Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2402.13252)
4. [VideoPrism: A Foundational Visual Encoder for Video Understanding](https://huggingface.co/papers/2402.13217)
5. [Video ReCap: Recursive Captioning of Hour-Long Videos](https://huggingface.co/papers/2402.13250)
6. [How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on Deceptive Prompts](https://huggingface.co/papers/2402.13220)
7. [The FinBen: An Holistic Financial Benchmark for Large Language Models](https://huggingface.co/papers/2402.12659)
8. [MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction](https://huggingface.co/login?next=%2Fpapers%2F2402.12712)
9. [TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization](https://huggingface.co/papers/2402.13249)
10. [A Touch, Vision, and Language Dataset for Multimodal Alignment](https://huggingface.co/papers/2402.13232)
11. [RealCompo: Dynamic Equilibrium between Realism and Compositionality Improves Text-to-Image Diffusion Models](https://huggingface.co/papers/2402.12908)

### 19 Feb 2024
1. [In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss](https://huggingface.co/papers/2402.10790)
2. [GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting](https://huggingface.co/login?next=%2Fpapers%2F2402.10259)
3. [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://huggingface.co/papers/2402.10379)
4. [LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models](https://huggingface.co/papers/2402.10524)
5. [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://huggingface.co/papers/2402.10466)
6. [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://huggingface.co/papers/2402.10294)
7. [Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation](https://huggingface.co/papers/2402.10491)
8. [Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots](https://huggingface.co/login?next=%2Fpapers%2F2402.10329)
9. [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter](https://huggingface.co/papers/2402.10896)
10. [RLVF: Learning from Verbal Feedback without Overgeneralization](https://huggingface.co/papers/2402.10893)
11. [SPAR: Personalized Content-Based Recommendation via Long Engagement Attention](https://huggingface.co/papers/2402.10555)
12. [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://huggingface.co/papers/2402.10644)

### 15 Feb 2024
1. [Magic-Me: Identity-Specific Video Customized Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.09368)
2. [Premise Order Matters in Reasoning with Large Language Models](https://huggingface.co/papers/2402.08939)
3. [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://huggingface.co/papers/2402.09052)
4. [Transformers Can Achieve Length Generalization But Not Robustly](https://huggingface.co/papers/2402.09371)
5. [Computing Power and the Governance of Artificial Intelligence](https://huggingface.co/papers/2402.08797)
6. [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://huggingface.co/login?next=%2Fpapers%2F2402.08714)
7. [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://huggingface.co/papers/2402.09126)
8. [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://huggingface.co/papers/2402.08855)
9. [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://huggingface.co/papers/2402.08958)

### 15 Feb 2024
1. [Magic-Me: Identity-Specific Video Customized Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2402.09368)
2. [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://huggingface.co/papers/2402.09052)
3. [Transformers Can Achieve Length Generalization But Not Robustly](https://huggingface.co/papers/2402.09371)
4. [Premise Order Matters in Reasoning with Large Language Models](https://huggingface.co/papers/2402.08939)
5. [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://huggingface.co/papers/2402.08855)
6. [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://huggingface.co/login?next=%2Fpapers%2F2402.08714)
7. [Computing Power and the Governance of Artificial Intelligence](https://huggingface.co/papers/2402.08797)
8. [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://huggingface.co/papers/2402.08958)
9. [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://huggingface.co/papers/2402.09126)

### 13 Feb 2024
1. [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://huggingface.co/papers/2402.07827)
2. [OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://huggingface.co/login?next=%2Fpapers%2F2402.07456)
3. [ChemLLM: A Chemical Large Language Model](https://huggingface.co/papers/2402.06852)
4. [Policy Improvement using Language Feedback Models](https://huggingface.co/papers/2402.07876)
5. [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://huggingface.co/papers/2402.07383)
6. [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://huggingface.co/papers/2402.07033)
7. [ODIN: Disentangled Reward Mitigates Hacking in RLHF](https://huggingface.co/papers/2402.07319)
8. [PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://huggingface.co/papers/2402.07872)
9. [Scaling Laws for Fine-Grained Mixture of Experts](https://huggingface.co/papers/2402.07871)
10. [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://huggingface.co/papers/2402.07625)
11. [A Tale of Tails: Model Collapse as a Change of Scaling Laws](https://huggingface.co/papers/2402.07043)
12. [Suppressing Pink Elephants with Direct Principle Feedback](https://huggingface.co/papers/2402.07896)
13. [LiRank: Industrial Large Scale Ranking Models at LinkedIn](https://huggingface.co/papers/2402.06859)
14. [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://huggingface.co/papers/2402.07865)
15. [Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping](https://huggingface.co/papers/2402.07610)
16. [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://huggingface.co/login?next=%2Fpapers%2F2402.07207)

### 12 Feb 2024
1. [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://huggingface.co/papers/2402.06118)
2. [HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://huggingface.co/papers/2402.06149)
3. [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://huggingface.co/papers/2402.06619)
4. [MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models](https://huggingface.co/papers/2402.06178)
5. [InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning](https://huggingface.co/papers/2402.06332)
6. [Keyframer: Empowering Animation Design using Large Language Models](https://huggingface.co/papers/2402.06071)
7. [SubGen: Token Generation in Sublinear Time and Memory](https://huggingface.co/papers/2402.06082)
8. [DeAL: Decoding-time Alignment for Large Language Models](https://huggingface.co/papers/2402.06147)
9. [Model Editing with Canonical Examples](https://huggingface.co/papers/2402.06155)
10. [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://huggingface.co/papers/2402.06088)
11. [Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning](https://huggingface.co/papers/2402.06102)
12. [Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss](https://huggingface.co/papers/2402.06187)

### 09 Feb 2024
1. [More Agents Is All You Need](https://huggingface.co/papers/2402.05120)
2. [$Œª$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space](https://huggingface.co/papers/2402.05195)
3. [Multilingual E5 Text Embeddings: A Technical Report](https://huggingface.co/papers/2402.05672)
4. [SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models](https://huggingface.co/papers/2402.05935)
5. [WebLINX: Real-World Website Navigation with Multi-Turn Dialogue](https://huggingface.co/login?next=%2Fpapers%2F2402.05930)
6. [Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains](https://huggingface.co/papers/2402.05140)
7. [An Interactive Agent Foundation Model](https://huggingface.co/papers/2402.05929)
8. [Memory Consolidation Enables Long-Context Video Understanding](https://huggingface.co/papers/2402.05861)
9. [Offline Actor-Critic Reinforcement Learning Scales to Large Models](https://huggingface.co/papers/2402.05546)
10. [In-Context Principle Learning from Mistakes](https://huggingface.co/papers/2402.05403)
11. [Implicit Diffusion: Efficient Optimization through Stochastic Sampling](https://huggingface.co/papers/2402.05468)
12. [SpiRit-LM: Interleaved Spoken and Written Language Model](https://huggingface.co/papers/2402.05755)
13. [Question Aware Vision Transformer for Multimodal Reasoning](https://huggingface.co/papers/2402.05472)
14. [InstaGen: Enhancing Object Detection by Training on Synthetic Dataset](https://huggingface.co/papers/2402.05937)
15. [Driving Everywhere with Large Language Model Policy Adaptation](https://huggingface.co/papers/2402.05932)

### 08 Feb 2024
1. [ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation](https://huggingface.co/papers/2402.04324)
2. [Direct Language Model Alignment from Online AI Feedback](https://huggingface.co/papers/2402.04792)
3. [BiLLM: Pushing the Limit of Post-Training Quantization for LLMs](https://huggingface.co/papers/2402.04291)
4. [ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://huggingface.co/papers/2402.04615)
5. [TP-Aware Dequantization](https://huggingface.co/papers/2402.04925)
6. [Fine-Tuned Language Models Generate Stable Inorganic Materials as Text](https://huggingface.co/papers/2402.04379)
7. [Hydragen: High-Throughput LLM Inference with Shared Prefixes](https://huggingface.co/papers/2402.05099)
8. [CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay](https://huggingface.co/papers/2402.04858)
9. [Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers](https://huggingface.co/papers/2402.04744)

### 05 Feb 2024
1. [StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback](https://huggingface.co/papers/2402.01391)
2. [Specialized Language Models with Cheap Inference from Limited Domain Data](https://huggingface.co/papers/2402.01093)
3. [Pok√©LLMon: A Human-Parity Agent for Pok√©mon Battles with Large Language Models](https://huggingface.co/papers/2402.01118)
4. [K-Level Reasoning with Large Language Models](https://huggingface.co/papers/2402.01521)
5. [TravelPlanner: A Benchmark for Real-World Planning with Language Agents](https://huggingface.co/papers/2402.01622)
6. [Boximator: Generating Rich and Controllable Motions for Video Synthesis](https://huggingface.co/login?next=%2Fpapers%2F2402.01566)
7. [Repeat After Me: Transformers are Better than State Space Models at Copying](https://huggingface.co/papers/2402.01032)
8. [EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks](https://huggingface.co/papers/2402.00892)
9. [Nomic Embed: Training a Reproducible Long Context Text Embedder](https://huggingface.co/papers/2402.01613)

### 04 Feb 2024
1. [OLMo: Accelerating the Science of Language Models](https://huggingface.co/papers/2402.00838)
2. [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://huggingface.co/papers/2402.00159)
3. [CroissantLLM: A Truly Bilingual French-English Language Model](https://huggingface.co/papers/2402.00786)
4. [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://huggingface.co/login?next=%2Fpapers%2F2402.00769)
5. [Can Large Language Models Understand Context?](https://huggingface.co/papers/2402.00858)
6. [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://huggingface.co/papers/2402.00854)
7. [Efficient Exploration for LLMs](https://huggingface.co/papers/2402.00396)
8. [Machine Unlearning for Image-to-Image Generative Models](https://huggingface.co/papers/2402.00351)
9. [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://huggingface.co/papers/2402.00867)
10. [Transforming and Combining Rewards for Aligning Large Language Models](https://huggingface.co/papers/2402.00742)
11. [EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models](https://huggingface.co/papers/2402.00518)

### 04 Feb 2024
1. [OLMo: Accelerating the Science of Language Models](https://huggingface.co/papers/2402.00838)
2. [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://huggingface.co/papers/2402.00159)
3. [CroissantLLM: A Truly Bilingual French-English Language Model](https://huggingface.co/papers/2402.00786)
4. [AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning](https://huggingface.co/login?next=%2Fpapers%2F2402.00769)
5. [Can Large Language Models Understand Context?](https://huggingface.co/papers/2402.00858)
6. [SymbolicAI: A framework for logic-based approaches combining generative models and solvers](https://huggingface.co/papers/2402.00854)
7. [Efficient Exploration for LLMs](https://huggingface.co/papers/2402.00396)
8. [Machine Unlearning for Image-to-Image Generative Models](https://huggingface.co/papers/2402.00351)
9. [AToM: Amortized Text-to-Mesh using 2D Diffusion](https://huggingface.co/papers/2402.00867)
10. [Transforming and Combining Rewards for Aligning Large Language Models](https://huggingface.co/papers/2402.00742)
11. [EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models](https://huggingface.co/papers/2402.00518)

### 31 Jan 2024
1. [Weaver: Foundation Models for Creative Writing](https://huggingface.co/papers/2401.17268)
2. [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://huggingface.co/login?next=%2Fpapers%2F2401.17053)
3. [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://huggingface.co/papers/2401.17270)
4. [Proactive Detection of Voice Cloning with Localized Watermarking](https://huggingface.co/papers/2401.17264)
5. [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://huggingface.co/papers/2401.17093)
6. [Weak-to-Strong Jailbreaking on Large Language Models](https://huggingface.co/papers/2401.17256)
7. [Transfer Learning for Text Diffusion Models](https://huggingface.co/papers/2401.17181)
8. [Repositioning the Subject within Image](https://huggingface.co/login?next=%2Fpapers%2F2401.16861)
9. [OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer](https://huggingface.co/papers/2401.16658)
10. [High-Quality Image Restoration Following Human Instructions](https://huggingface.co/papers/2401.16468)
11. [H2O-Danube-1.8B Technical Report](https://huggingface.co/papers/2401.16818)
12. [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://huggingface.co/papers/2401.16467)
13. [MouSi: Poly-Visual-Expert Vision-Language Models](https://huggingface.co/papers/2401.17221)
14. [T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives](https://huggingface.co/papers/2401.16677)

### 27 Jan 2024
1. [Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://huggingface.co/login?next=%2Fpapers%2F2401.13795)
2. [Rethinking Patch Dependence for Masked Autoencoders](https://huggingface.co/papers/2401.14391)
3. [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence](https://huggingface.co/papers/2401.14196)
4. [Deconstructing Denoising Diffusion Models for Self-Supervised Learning](https://huggingface.co/papers/2401.14404)
5. [Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI](https://huggingface.co/login?next=%2Fpapers%2F2401.14019)
6. [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://huggingface.co/papers/2401.13919)
7. [Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities](https://huggingface.co/papers/2401.14405)
8. [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](https://huggingface.co/papers/2401.13974)
9. [pix2gestalt: Amodal Segmentation by Synthesizing Wholes](https://huggingface.co/login?next=%2Fpapers%2F2401.14398)
10. [FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design](https://huggingface.co/papers/2401.14112)
11. [Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation](https://huggingface.co/papers/2401.14257)
12. [Adaptive Mobile Manipulation for Articulated Objects In the Open World](https://huggingface.co/login?next=%2Fpapers%2F2401.14403)
13. [Genie: Achieving Human Parity in Content-Grounded Datasets Generation](https://huggingface.co/papers/2401.14367)
14. [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion](https://huggingface.co/papers/2401.14066)

### 25 Jan 2024
1. [Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://huggingface.co/papers/2401.13627)
2. [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://huggingface.co/papers/2401.13601)
3. [MambaByte: Token-free Selective State Space Model](https://huggingface.co/papers/2401.13660)
4. [SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection](https://huggingface.co/papers/2401.13160)
5. [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://huggingface.co/papers/2401.13388)
6. [MaLA-500: Massive Language Adaptation of Large Language Models](https://huggingface.co/papers/2401.13303)
7. [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://huggingface.co/papers/2401.13311)

### 20 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
3. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
4. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
5. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
6. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
7. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
8. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
9. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)
10. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)

### 20 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
3. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
4. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
5. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
6. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
7. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
8. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
9. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)
10. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)

### 19 Jan 2024
1. [Self-Rewarding Language Models](https://huggingface.co/papers/2401.10020)
2. [DiffusionGPT: LLM-Driven Text-to-Image Generation System](https://huggingface.co/papers/2401.10061)
3. [ChatQA: Building GPT-4 Level Conversational QA Models](https://huggingface.co/papers/2401.10225)
4. [VMamba: Visual State Space Model](https://huggingface.co/papers/2401.10166)
5. [WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens](https://huggingface.co/papers/2401.09985)
6. [Improving fine-grained understanding in image-text pre-training](https://huggingface.co/papers/2401.09865)
7. [SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://huggingface.co/login?next=%2Fpapers%2F2401.10171)
8. [FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder](https://huggingface.co/papers/2401.10032)
9. [CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://huggingface.co/login?next=%2Fpapers%2F2401.09962)
10. [Rethinking FID: Towards a Better Evaluation Metric for Image Generation](https://huggingface.co/papers/2401.09603)

### 18 Jan 2024
1. [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://huggingface.co/papers/2401.09417)
2. [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://huggingface.co/papers/2401.09340)
3. [ReFT: Reasoning with Reinforced Fine-Tuning](https://huggingface.co/papers/2401.08967)
4. [UniVG: Towards UNIfied-modal Video Generation](https://huggingface.co/papers/2401.09084)
5. [Asynchronous Local-SGD Training for Language Modeling](https://huggingface.co/papers/2401.09135)
6. [DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference](https://huggingface.co/papers/2401.08671)
7. [VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models](https://huggingface.co/papers/2401.09047)
8. [GARField: Group Anything with Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.09419)
9. [SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers](https://huggingface.co/papers/2401.08740)
10. [Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://huggingface.co/papers/2401.09048)
11. [ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://huggingface.co/papers/2401.08937)
12. [TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://huggingface.co/login?next=%2Fpapers%2F2401.09416)

### 16 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
7. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
8. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
9. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
10. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
11. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 14 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
4. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
5. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
11. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
14. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
15. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
18. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)

### 13 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
8. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
9. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
10. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
11. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
12. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
13. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
16. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
17. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 12 Jan 2024
1. [TrustLLM: Trustworthiness in Large Language Models](https://huggingface.co/papers/2401.05561)
2. [PALP: Prompt Aligned Personalization of Text-to-Image Models](https://huggingface.co/login?next=%2Fpapers%2F2401.06105)
3. [Transformers are Multi-State RNNs](https://huggingface.co/papers/2401.06104)
4. [Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation](https://huggingface.co/papers/2401.05675)
5. [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://huggingface.co/papers/2401.06066)
6. [TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering](https://huggingface.co/login?next=%2Fpapers%2F2401.06003)
7. [TOFU: A Task of Fictitious Unlearning for LLMs](https://huggingface.co/papers/2401.06121)
8. [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://huggingface.co/papers/2401.06102)
9. [Towards Conversational Diagnostic AI](https://huggingface.co/papers/2401.05654)
10. [Distilling Vision-Language Models on Millions of Videos](https://huggingface.co/papers/2401.06129)
11. [Object-Centric Diffusion for Efficient Video Editing](https://huggingface.co/papers/2401.05735)
12. [Diffusion Priors for Dynamic View Synthesis from Monocular Videos](https://huggingface.co/papers/2401.05583)
13. [Secrets of RLHF in Large Language Models Part II: Reward Modeling](https://huggingface.co/papers/2401.06080)
14. [LEGO:Language Enhanced Multi-modal Grounding Model](https://huggingface.co/papers/2401.06071)
15. [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://huggingface.co/papers/2401.05749)
16. [Efficient LLM inference solution on Intel GPU](https://huggingface.co/papers/2401.05391)
17. [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](https://huggingface.co/papers/2401.05811)
18. [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://huggingface.co/papers/2401.05566)

### 11 Jan 2024
1. [PIXART-Œ¥: Fast and Controllable Image Generation with Latent Consistency Models](https://huggingface.co/papers/2401.05252)
2. [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://huggingface.co/login?next=%2Fpapers%2F2401.05335)
3. [URHand: Universal Relightable Hands](https://huggingface.co/login?next=%2Fpapers%2F2401.05334)
4. [The Impact of Reasoning Step Length on Large Language Models](https://huggingface.co/papers/2401.04925)
5. [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://huggingface.co/papers/2401.05033)
6. [Score Distillation Sampling with Learned Manifold Corrective](https://huggingface.co/papers/2401.05293)
7. [ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://huggingface.co/papers/2401.05314)

### 10 Jan 2024
1. [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation](https://huggingface.co/papers/2401.04468)
2. [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models](https://huggingface.co/papers/2401.04658)
3. [Masked Audio Generation using a Single Non-Autoregressive Transformer](https://huggingface.co/papers/2401.04577)
4. [Jump Cut Smoothing for Talking Heads](https://huggingface.co/login?next=%2Fpapers%2F2401.04718)
5. [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding](https://huggingface.co/papers/2401.04575)
6. [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding](https://huggingface.co/papers/2401.04398)
7. [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://huggingface.co/papers/2401.04695)
8. [FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for Acoustic Echo Cancellation](https://huggingface.co/papers/2401.04283)

### 09 Jan 2024
1. [Mixtral of Experts](https://huggingface.co/papers/2401.04088)
2. [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://huggingface.co/papers/2401.04081)
3. [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://huggingface.co/papers/2401.02994)
4. [GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation](https://huggingface.co/papers/2401.04092)
5. [Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon](https://huggingface.co/papers/2401.03462)
6. [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://huggingface.co/papers/2401.03506)
7. [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](https://huggingface.co/papers/2401.03065)
8. [TeleChat Technical Report](https://huggingface.co/papers/2401.03804)
9. [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach](https://huggingface.co/papers/2401.02987)
10. [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding](https://huggingface.co/papers/2401.03003)
11. [AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://huggingface.co/login?next=%2Fpapers%2F2401.04099)

### 08 Jan 2024
1. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://huggingface.co/papers/2401.02954)
2. [Denoising Vision Transformers](https://huggingface.co/papers/2401.02957)
3. [Progressive Knowledge Distillation Of Stable Diffusion XL Using Layer Level Loss](https://huggingface.co/papers/2401.02677)
4. [DocGraphLM: Documental Graph Language Model for Information Extraction](https://huggingface.co/papers/2401.02823)
5. [Pheme: Efficient and Conversational Speech Generation](https://huggingface.co/papers/2401.02839)
6. [Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively](https://huggingface.co/login?next=%2Fpapers%2F2401.02955)
7. [Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache](https://huggingface.co/papers/2401.02669)

### 07 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
9. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
12. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 06 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
5. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
6. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
10. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
11. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 05 Jan 2024
1. [TinyLlama: An Open-Source Small Language Model](https://huggingface.co/papers/2401.02385)
2. [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://huggingface.co/papers/2401.02038)
3. [LLaMA Pro: Progressive LLaMA with Block Expansion](https://huggingface.co/papers/2401.02415)
4. [LLM Augmented LLMs: Expanding Capabilities through Composition](https://huggingface.co/papers/2401.02412)
5. [Instruct-Imagen: Image Generation with Multi-modal Instruction](https://huggingface.co/papers/2401.01952)
6. [Improving Diffusion-Based Image Synthesis with Context Prediction](https://huggingface.co/papers/2401.02015)
7. [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs](https://huggingface.co/papers/2401.02411)
8. [ODIN: A Single Model for 2D and 3D Perception](https://huggingface.co/papers/2401.02416)
9. [ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers](https://huggingface.co/papers/2401.02072)
10. [Learning the 3D Fauna of the Web](https://huggingface.co/login?next=%2Fpapers%2F2401.02400)
11. [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://huggingface.co/login?next=%2Fpapers%2F2401.02117)
12. [LLaVA-$œÜ$: Efficient Multi-Modal Assistant with Small Language Model](https://huggingface.co/papers/2401.02330)
13. [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://huggingface.co/papers/2401.01974)
14. [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://huggingface.co/papers/2401.01970)

### 04 Jan 2024
1. [From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations](https://huggingface.co/papers/2401.01885)
2. [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://huggingface.co/login?next=%2Fpapers%2F2401.01614)
3. [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/papers/2401.01808)
4. [Image Sculpting: Precise Object Editing with 3D Geometry Control](https://huggingface.co/login?next=%2Fpapers%2F2401.01702)
5. [Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions](https://huggingface.co/papers/2401.01827)
6. [SIGNeRF: Scene Integrated Generation for Neural Radiance Fields](https://huggingface.co/login?next=%2Fpapers%2F2401.01647)
7. [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://huggingface.co/papers/2401.01854)
8. [Incremental FastPitch: Chunk-based High Quality Text to Speech](https://huggingface.co/papers/2401.01755)
9. [CoMoSVC: Consistency Model-based Singing Voice Conversion](https://huggingface.co/papers/2401.01792)
10. [Efficient Hybrid Zoom using Camera Fusion on Mobile Phones](https://huggingface.co/papers/2401.01461)
11. [A Vision Check-up for Language Models](https://huggingface.co/papers/2401.01862)
12. [WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope](https://huggingface.co/papers/2401.01699)

### 03 Jan 2024
1. [DocLLM: A layout-aware generative language model for multimodal document understanding](https://huggingface.co/papers/2401.00908)
2. [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://huggingface.co/papers/2401.01335)
3. [Boundary Attention: Learning to Find Faint Boundaries at Any Resolution](https://huggingface.co/papers/2401.00935)
4. [LLaMA Beyond English: An Empirical Study on Language Capability Transfer](https://huggingface.co/papers/2401.01055)
5. [Q-Refine: A Perceptual Quality Refiner for AI-Generated Image](https://huggingface.co/papers/2401.01117)
6. [TrailBlazer: Trajectory Control for Diffusion-Based Video Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00896)
7. [Taming Mode Collapse in Score Distillation for Text-to-3D Generation](https://huggingface.co/login?next=%2Fpapers%2F2401.00909)
8. [A Comprehensive Study of Knowledge Editing for Large Language Models](https://huggingface.co/papers/2401.01286)
9. [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://huggingface.co/papers/2401.01325)
10. [En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data](https://huggingface.co/papers/2401.01173)
11. [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM](https://huggingface.co/papers/2401.01256)

### 02 Jan 2024
1. [LARP: Language-Agent Role Play for Open-World Games](https://huggingface.co/papers/2312.17653)
2. [FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis](https://huggingface.co/papers/2312.17681)
3. [PanGu-$œÄ$: Enhancing Language Model Architectures via Nonlinearity Compensation](https://huggingface.co/papers/2312.17276)
4. [Learning Vision from Models Rivals Learning Vision from Data](https://huggingface.co/papers/2312.17742)
5. [Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models](https://huggingface.co/papers/2312.17661)




## How to Contribute
Your contributions are highly valued! Feel free to contribute to the repository if you come across an interesting paper, article, or book. Follow these steps:
1. Fork the repository.
2. Add the paper, article, or book information to the corresponding section.
3. Create a pull request, and your contribution will be reviewed and merged.
4. Note: Please do not try to update the structure of the readme file.

Let's build an ever-growing resource together! √∞≈∏‚Äú≈°√¢≈ì¬®

Enjoy exploring the world of AI!‚úàÔ∏è


